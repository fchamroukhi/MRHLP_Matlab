function mrhlp = learn_MRHLP_EM(x, y, K, p, dim_w, type_variance, total_EM_tries, max_iter_EM,...
    threshold, verbose_EM, verbose_IRLS)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%function mrhlp = learn_MRHLP_EM(x, y, K, p, dim_w, type_variance, total_EM_tries, max_iter_EM, threshold, verbose_EM, verbose_IRLS)%
%
% Learn a Multiple Regression model with a Hidden Logistic Process (MRHLP) for modeling and segmentation of a time series with regime changes.
% The learning is performed by the EM algorithm.
%
% Inputs :
%
%          1. (x,y) : a time series composed of m points : dim(y)=[m d]
%                * Each curve is observed during the interval [0,T], i.e x =[t_1,...,t_m]
%                * t{j}-t_{j-1} = dt (sampling period)
%
%          2. K : Number of polynomial regression components (regimes)
%          3. p : degree of the polynomials
%          4. q :  order of the logistic regression (choose 1 for
%          convex segmentation)
%          5. total_EM_tries :  (the solution providing the highest log-lik
%          is chosen
%          6. verbose_EM : set to 1 for printing the "log-lik"  values during
%          EM iterations (by default verbose_EM = 0)
%          7. verbose_IRLS : set to 1 for printing the values of the criterion
%             optimized by IRLS at each IRLS iteration. (IRLS is used at
%             each M step of EM). (By default: verbose_EM = 0)
%
% Outputs :
%
%          1. mrhlp : structure containing mainly the following fields:
%                      1.1 param : the model parameters:(W,beta1,...,betaK,sigma2_1,...,sigma2_K).
%                          param is a structure containing the following
%                          fields:
%                          1.1.1 wk = (w1,...,wK-1) parameters of the logistic process:
%                          matrix of dimension [(q+1)x(K-1)] with q the
%                          order of logistic regression.
%                          1.1.2 betak = (beta1,...,betaK) polynomial
%                          regression coefficient matrices: each matrix of
%                          dimension [(p+1)xd] p being the polynomial
%                          degree and d the dimmension of the time series
%                          1.1.3 sigmak : the covariance matrix for regime k. dimnesion [dxd]
%
%          4. tjk : post prob (fuzzy segmentation matrix of dim [mxK])
%          5. Zjk : Hard segmentation matrix of dim [mxK] obtained by the
%          MAP rule :  z_{jk} = 1 if z_j = arg max_k tjk; O otherwise
%          (k =1,...,K)
%          6. klas : column vector of the labels issued from Zjk, its
%          elements are klas(j)= k (k=1,...,K.)
%          8. theta : parameter vector of the model: theta=(wk,betak,sigma2k).
%              column vector of dim [nu x 1] with nu = nbr of free parametres
%
%          9. Ey: curve expectation : sum of the polynomial components betak ri weighted by
%             the logitic probabilities pijk: Ey(j) = sum_{k=1}^K pijk betak rj, j=1,...,m. Ey
%              is a column vector of dimension m
%          10. loglik : log-lik at convergence of EM
%          11. stored_loglik : vector of stored valued of the log-lik at each EM
%          iteration
%
%          12. BIC : valeur du critre BIC.  BIC = loglik - nu*log(nm)/2.
%          13. ICL : valeur du critre ICL.  BIC = complete_loglik - nu*log(nm)/2.
%          14. AIC : valeur du critere AIC. AIC = loglik - nu.
%          15. nu : nbr of free model parametres

%          16. Xw : design matrix for the logistic regression: matrix of dim [mx(q+1)].
%          17. XBeta : design matrix for the polynomial regression: matrix of dim [mx(p+1)].


%% References
% Please cite the following papers for this code:
%
% @article{Chamroukhi-MRHLP-2013,
% 	Author = {F. Chamroukhi and D. Trabelsi and S. Mohammed and L. Oukhellou and Y. Amirat},
% 	Journal = {Neurocomputing},
% 	Month = {November},
% 	Pages = {633--644},
% 	Publisher = {Elsevier},
% 	Title = {Joint segmentation of multivariate time series with hidden process regression for human activity recognition},
% 	Volume = {120},
% 	Year = {2013},
% 	note = {},
% 	url  = {https://chamroukhi.com/papers/chamroukhi_et_al_neucomp2013b.pdf}
% 	}
% 
% @article{Chamroukhi-FDA-2018,
%  	Journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
%  	Author = {Faicel Chamroukhi and Hien D. Nguyen},
%  	Note = {DOI: 10.1002/widm.1298.},
%  	Volume = {},
%  	Title = {Model-Based Clustering and Classification of Functional Data},
%  	Year = {2019},
%  	Month = {to appear},
%  	url =  {https://chamroukhi.com/papers/MBCC-FDA.pdf}
%     }
% 
% @article{chamroukhi_et_al_NN2009,
% 	Address = {Oxford, UK, UK},
% 	Author = {Chamroukhi, F. and Sam\'{e}, A. and Govaert, G. and Aknin, P.},
% 	Date-Added = {2014-10-22 20:08:41 +0000},
% 	Date-Modified = {2014-10-22 20:08:41 +0000},
% 	Journal = {Neural Networks},
% 	Number = {5-6},
% 	Pages = {593--602},
% 	Publisher = {Elsevier Science Ltd.},
% 	Title = {Time series modeling by a regression approach based on a latent process},
% 	Volume = {22},
% 	Year = {2009},
% 	url  = {https://chamroukhi.users.lmno.cnrs.fr/papers/Chamroukhi_Neural_Networks_2009.pdf}
% 	}
% 
%
%
% Faicel CHAMROUKHI
% Mise ??? jour (2010)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

warning off

switch type_variance
    case 'homoskedastic'
        homoskedastic =1;
    case 'hetereskedastic'
        homoskedastic=0;
    otherwise
        error('The type of the model variance should be : ''homoskedastic'' ou ''hetereskedastic''');
end

if nargin<11; verbose_IRLS = 0; end
if nargin<10; verbose_IRLS = 0; verbose_EM = 0; end
if nargin<9;  verbose_IRLS = 0; verbose_EM = 0;   threshold = 1e-6; end
if nargin<8;  verbose_IRLS = 0; verbose_EM = 0;   threshold = 1e-6; max_iter_EM = 1000; end
if nargin<7;  verbose_IRLS = 0; verbose_EM = 0;   threshold = 1e-6; max_iter_EM = 1000; total_EM_tries=1;end

if size(y,2)>size(y,1), y=y'; end %

[m, d] = size(y);


q = dim_w;

[XBeta, Xw] = designmatrix_RHLP(x,p,q);

%
best_loglik = -inf;
nb_good_try=0;
total_nb_try=0;
cputime_total = [];
try_EM = 1;
while (nb_good_try < total_EM_tries)
    if total_EM_tries>1,fprintf(1, 'EM try n°  %d \n ',nb_good_try+1); end
    total_nb_try=total_nb_try+1;
    time = cputime;
    %% EM Initializaiton step
    
    %   1. Initialization of W
    if try_EM ==1
        W0 = rand(q+1,K-1);
    else
        W0 = rand(q+1,K-1);
    end
    mdel.wk = W0;
    %   2. Initialization of betak and sigma2k (from one curve)
    param = init_regression_param_MRHLP(XBeta, y, K, type_variance, try_EM);
    
    %%%
    iter = 0;
    converge = 0;
    prev_loglik=-inf;
    top=0;
    Winit = W0;%
    %% EM %%%%
    while ~converge && ~isempty(param) && (iter< max_iter_EM)
        %% E-Step
        param.piik = logit_model(Winit,Xw);
        
        log_piik_fik =zeros(m,K);
        for k = 1:K
            muk = XBeta*mdel.betak{k};
            if homoskedastic
                sigmak =  mdel.sigmak;
            else
                sigmak = mdel.sigmak{k};
            end
                 z =((y-muk)*inv(sigmak)).*(y-muk);
                 mahalanobis = sum(z,2);
                 denom = (2*pi)^(d/2)*(det(sigmak))^(1/2);  

                 log_piik_fik(:,k) = log(param.piik(:,k))- ones(m,1)*log(denom)- 0.5*mahalanobis;  
        end
        
        %%log_piik_fik  = min(log_piik_fik,log(realmax));
        log_piik_fik = max(log_piik_fik ,log(realmin));
        %         piik_fik = exp(log_piik_fik);
        %         fxi =sum(piik_fik,2);
        %         log_fxi=log(fxi);
        %         log_sum_piik_fik = log(sum(piik_fik,2));
        %         log_tik = log_piik_fik - log_sum_piik_fik*ones(1,K);
        %         tik = normalize(exp(log_tik),2);
        %       log_piik_fik = max(log_piik_fik ,log(realmin));
        %     log_piik_fik = min(log_piik_fik ,log(realmax));
        
        piik_fik = exp(log_piik_fik);
        fxi = sum(piik_fik,2);
        log_sum_piik_fik = log(sum(piik_fik,2));
        log_tik = log_piik_fik - log_sum_piik_fik*ones(1,K);
        %log_tauik = max(log_tauik ,log(realmin));
        tik = normalize(exp(log_tik),2);
        
        %% M-Step
        % Maximization w.r.t betak and sigma2k (the variances)
        % --------------------------------------------------%
        if homoskedastic,  s = 0;   end
        %
        for k=1:K
            weights = tik(:,k);% post prob of each component k (dimension nx1)
            nk = sum(weights);% expected cardinal numnber of class k
            
            Xwk = XBeta.*(sqrt(weights)*ones(1,p+1));%[m*(p+1)]
            ywk = y.*(sqrt(weights)*ones(1,d));% dimension :(nxd).*(nxd) = (nxd)
            %if rcond(M)<1e-16
            betak = inv(Xwk'*Xwk + 1e-9*eye(p+1))*Xwk'*ywk; % Maximization w.r.t betak
            mdel.betak{k}=betak;
            z = (y-XBeta*betak).*(sqrt(weights)*ones(1,d));
            % Maximisation w.r.t sigma2k (the variances)
            
            sk = z'*z;
            if homoskedastic
                s = s+sk;
                mdel.sigmak = s/m;
            else
                mdel.sigmak{k}=sk/nk;
            end
            
            %                                  k
            %                      mdel.sigmak{k}
            %             pause
        end
        % Maximization w.r.t W
        % ----------------------------------%
        
        %%  IRLS : Iteratively Reweighted Least Squares (for IRLS, see the IJCNN 2009 paper)
        res = IRLS(Xw, tik, Winit, verbose_IRLS);
        param.piik = res.piik;
        mdel.wk = res.W;
        Winit = res.W;
        
        
        %% End of EM
        iter=iter+1;
        
        %% log-likelihood
        
        %if (priorsigma~=0); regEM = log(priorsigma); else regEM = 0; end
        
        loglik = sum(log_sum_piik_fik) + res.reg_irls;% + regEM;
        %%
        if prev_loglik-loglik > 1e-4
            top = top+1;
            if (top==10)
                %fprintf(1, '!!!!! The loglikelihood is decreasing from %6.4f to %6.4f!\n', prev_loglik, loglik);
                break;
            end
        end
        %%
        if verbose_EM,fprintf(1, 'EM   : Iteration : %d   Log-likelihood : %f \n',  iter,loglik); end
        converge = abs((loglik-prev_loglik)/prev_loglik) <= threshold;
        
        prev_loglik = loglik;
        stored_loglik(iter) = loglik;
        
    end% end of an EM run
    try_EM = try_EM +1;
    cputime_total = [cputime_total cputime-time];
    
    
    mrhlp.stats.loglik = loglik;
    mrhlp.stats.stored_loglik = stored_loglik;
    mrhlp.param = param;
    mrhlp.stats.log_piik_fik = log_piik_fik;
    
    %% estimated parameter vector
    theta = [mdel.wk(:); mdel.betak(:); mdel.sigmak(:)];
    
    mrhlp.theta = theta;
    % mrhlp.param.piik = param.piik(1:m,:);
    mrhlp.stats.tik = tik(1:m,:);
    
    if total_EM_tries>1
        fprintf(1,'loglik = %f \n',mrhlp.stats.loglik);
    end
    if ~isempty(mrhlp.param)
        nb_good_try=nb_good_try+1;
        total_nb_try=0;
        
        if loglik > best_loglik
            best_mrhlp = mrhlp;
            best_loglik = loglik;
        end
    end
    
    if total_nb_try > 500
        fprintf('can''t obtain the requested number of classes \n');
        mrhlp=[];
        return
    end
end%end of the EM loop


mrhlp = best_mrhlp;
%
if total_EM_tries>1;   fprintf(1,'best loglik:  %f\n',mrhlp.stats.loglik); end

% % for the best mrhlp
mrhlp.param.piik = mrhlp.param.piik(1:m,:);
mrhlp.stats.tik = mrhlp.stats.tik(1:m,:);

%% classsification pour EM : classes = argmax(piik) (here to ensure a convex segmentation of the curve(s)).
[klas, Zik] = MAP(mrhlp.param.piik);

mrhlp.stats.klas = klas;

% model parammeter vector
theta = [mdel.wk(:); mdel.betak(:); mdel.sigmakk(:)];

mrhlp.theta = theta;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

for k = 1:K
    regimesk =  XBeta*mrhlp.param.betak{k};
    mrhlp.stats.polynomials(:,:,k) = regimesk;
    mrhlp.stats.weighted_polynomials(:,:,k) = (mrhlp.param.piik(:,k)*ones(1,d)).*regimesk;
end
mrhlp.stats.Ey =sum(mrhlp.stats.weighted_polynomials,3);%sum over the regimes k

mrhlp.stats.cputime = mean(cputime_total);
mrhlp.stats.cputime_total = cputime_total;

% mrhlp.stats.log_fxi = log_fxi(1:m,:);
% mrhlp.stats.fxi = fxi(1:m,:);

%%% BIC AIC, ICL
% number of free model parameters
if homoskedastic
    nu = (p+q+3)*K-(q+1) - (K-1) ;
else
    nu = (p+q+3)*K-(q+1);
end
mrhlp.stats.BIC = mrhlp.stats.loglik - (nu*log(m)/2);
mrhlp.stats.AIC = mrhlp.stats.loglik - nu;
%% CL(theta) : Completed-data loglikelihood
zik_log_piik_fk = Zik.*mrhlp.stats.log_piik_fik;
sum_zik_log_fik = sum(zik_log_piik_fk,2);
comp_loglik = sum(sum_zik_log_fik);
mrhlp.stats.comp_loglik = comp_loglik;
mrhlp.stats.ICL = mrhlp.stats.comp_loglik - (nu*log(m)/2);
%warning on
%
mrhlp.stats.nu = nu;
mrhlp.design.XBeta = XBeta;
mrhlp.design.Xw = Xw;



